{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmapPy.pandasGEXpress.parse\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import scipy\n",
    "import sklearn.cluster\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data(num_rows, path):\n",
    "    gctoo = cmapPy.pandasGEXpress.parse.parse(path)\n",
    "    print(\"gctoo{}\".format(gctoo))\n",
    "    data_df_rows_chopped = gctoo.data_df.head(num_rows)\n",
    "\n",
    "    return data_df_rows_chopped, gctoo\n",
    "\n",
    "def run_AffinityProp(row_or_col, data_df):\n",
    "    if row_or_col == \"col\":\n",
    "        data_df = data_df.transpose()\n",
    "\n",
    "    Affinity_prop = sklearn.cluster.AffinityPropagation(affinity = \"euclidean\", random_state = 0).fit(data_df.to_numpy())\n",
    "\n",
    "    return Affinity_prop\n",
    "\n",
    "def sort_and_drop(name_col, name_row, data_df):\n",
    "\n",
    "    sorted_df = data_df.sort_values(name_col)\n",
    "    sorted_df = sorted_df.sort_values(name_row, axis = 1)\n",
    "\n",
    "    print(\"sorted_df with labels: {}\".format(sorted_df))\n",
    "\n",
    "    sorted_df = sorted_df.drop(name_row, axis = 0)\n",
    "    sorted_df = sorted_df.drop(name_col, axis = 1)\n",
    "\n",
    "    print(\"sorted_df: {}\".format(sorted_df))\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "def sort_by_label_list(df_to_sort, row_labels, col_labels):\n",
    "\n",
    "    num_col = len(df_to_sort.columns)\n",
    "    num_row = len(df_to_sort.index)\n",
    "\n",
    "    print(\"num_col: {}\".format(num_col))\n",
    "    print(\"num_row: {}\".format(num_row))\n",
    "    \n",
    "    print(row_labels)\n",
    "    \n",
    "\n",
    "    col_labels_df = pd.DataFrame(col_labels)\n",
    "    col_labels_df.rename(columns = {0:num_row}, inplace = True)\n",
    "    col_labels_df.index = df_to_sort.columns\n",
    "    col_labels_df = col_labels_df.transpose()\n",
    "\n",
    "    row_labels_df = pd.DataFrame(row_labels)\n",
    "    row_labels_df.rename(columns = {0:num_col}, inplace = True)\n",
    "    row_labels_df.index = df_to_sort.index\n",
    "\n",
    "    col_labels_df.insert( num_col, num_col, 20000)\n",
    "\n",
    "    print(\"df_to_sort: {}\".format(df_to_sort))\n",
    "    print(\"col_labels_df: {}\".format(col_labels_df))\n",
    "    print(\"row_labels_df: {}\".format(row_labels_df))\n",
    "\n",
    "\n",
    "    label_df = df_to_sort.join(row_labels_df)\n",
    "\n",
    "    label_df = label_df.append(col_labels_df)\n",
    "\n",
    "    print(\"label_df: {}\".format(label_df))\n",
    "\n",
    "    sorted_df = sort_and_drop(num_col, num_row, label_df)\n",
    "\n",
    "    return sorted_df, label_df\n",
    "\n",
    "def get_cluster_centers(data_df, AffinityProp_cluster_centers_indices):\n",
    "    \n",
    "    cluster_centers = []\n",
    "    \n",
    "\n",
    "    print(\"AffinityProp_cluster_centers_indices: {}\".format(AffinityProp_cluster_centers_indices))\n",
    "    print(\"len(AffinityProp_cluster_centers_indices): {}\".format(len(AffinityProp_cluster_centers_indices)))\n",
    "    for i in range (0, len(AffinityProp_cluster_centers_indices)):\n",
    "        cluster_column = (data_df.iloc[:, AffinityProp_cluster_centers_indices[i]]).to_numpy()\n",
    "        cluster_centers.append(cluster_column)\n",
    "\n",
    "    return cluster_centers\n",
    "\n",
    "def get_child_counts(linkage_matrix):\n",
    "    childs = []\n",
    "\n",
    "    for i in range(0, len(linkage_matrix)):\n",
    "        childs.append((int(linkage_matrix.loc[i, 0]), int(linkage_matrix.loc[i, 1])))\n",
    "\n",
    "     # create the counts of samples under each node\n",
    "    counts = numpy.zeros(len(childs))\n",
    "    print(\"counts: {}\".format(counts))\n",
    "    n_samples = len(linkage_matrix) + 1\n",
    "    for i, merge in enumerate(childs):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    counts_df = pd.DataFrame(counts)\n",
    "    counts_df.columns = [3]\n",
    "\n",
    "    linkage_matrix.update(counts_df)\n",
    "\n",
    "    return linkage_matrix\n",
    "\n",
    "def run_scipy_cluster_dendrogram(linkage_matrix):\n",
    "    r_dict = dendrogram(linkage_matrix, distance_sort = \"ascending\")\n",
    "    return r_dict\n",
    "\n",
    "def super_cluster(cluster_centers):\n",
    "    #run and get ward_super_clusters\n",
    "    #modify matrix to pass into\n",
    "    ward_super_clusters = sklearn.cluster.AgglomerativeClustering(affinity = \"euclidean\", n_clusters = len(cluster_centers), linkage = \"average\", compute_full_tree = True, compute_distances = True).fit(cluster_centers)\n",
    "\n",
    "    children_df = pd.DataFrame(ward_super_clusters.children_)\n",
    "    children_df[2] = ward_super_clusters.distances_\n",
    "    children_df[3] = numpy.NaN\n",
    "\n",
    "    super_linkage_matrix_with_counts = get_child_counts(children_df)\n",
    "\n",
    "    print(\"super_linkage_matrix_with_counts: \\n{}\".format(super_linkage_matrix_with_counts))\n",
    "\n",
    "    super_r_dict = run_scipy_cluster_dendrogram(super_linkage_matrix_with_counts)\n",
    "\n",
    "    return super_linkage_matrix_with_counts, super_r_dict\n",
    "\n",
    "def change_labels(label):\n",
    "    #given labels such as [0, 2, 5, 1, 3, 4]\n",
    "    #change it so index is the number, and value is where it would go \n",
    "    #so [0, 3, 1, 4, 5, 2]\n",
    "    label_index = []\n",
    "\n",
    "    for i in range(0, len(label)):\n",
    "        label_index.append(label.index(i))\n",
    "        \n",
    "\n",
    "    print(\"label_index : {}\".format(label_index))\n",
    "\n",
    "\n",
    "\n",
    "    return label_index\n",
    "\n",
    "def reorder_super_cluster(label_df, super_dendro_labels_index):\n",
    "    num_col = len(label_df.columns) - 1\n",
    "    num_row = len(label_df.index) - 1\n",
    "    \n",
    "    print(\"num_col, num_row\")\n",
    "    \n",
    "    print(num_col)\n",
    "    print(num_row)\n",
    "\n",
    "    for i in range(0, num_col + 1):\n",
    "        val = int(label_df.iloc[num_row, i])\n",
    "        if val != 20000 and val != numpy.NaN:\n",
    "            label_df.iloc[num_row, (i)] = super_dendro_labels_index[val]\n",
    "            #label_df.iloc[i, num_col] = super_dendro_labels_index[val]\n",
    "            \n",
    "    print(\"label_df: {}\".format(label_df))\n",
    "\n",
    "    return label_df\n",
    "\n",
    "def update_super_matrix(super_linkage_matrix_with_counts, super_dendro_labels_index):\n",
    "    while super_linkage_matrix_with_counts[2][len(super_linkage_matrix_with_counts) - 1] > 4:\n",
    "        super_linkage_matrix_with_counts[2] = super_linkage_matrix_with_counts[2] / 2\n",
    "    \n",
    "    for i in range(0, len(super_linkage_matrix_with_counts)):\n",
    "        zero_leaf = super_linkage_matrix_with_counts.iloc[i, 0]\n",
    "        one_leaf = super_linkage_matrix_with_counts.iloc[i, 1]\n",
    "        if zero_leaf < len(super_dendro_labels_index):\n",
    "            super_linkage_matrix_with_counts.at[i, 0] = super_dendro_labels_index[int(zero_leaf)]\n",
    "        if one_leaf < len(super_dendro_labels_index):\n",
    "            super_linkage_matrix_with_counts.at[i, 1] = super_dendro_labels_index[int(one_leaf)]\n",
    "\n",
    "    super_linkage_matrix_with_counts[4] = numpy.NaN\n",
    "    super_linkage_matrix_with_counts[5] = numpy.NaN\n",
    "\n",
    "    #adding 5 to dist values of app super matrix \n",
    "    super_linkage_matrix_with_counts[2] = super_linkage_matrix_with_counts[2] + 5\n",
    "\n",
    "    return super_linkage_matrix_with_counts\n",
    "\n",
    "def prepare_where(df_super_linkage_matrix, current_sub):\n",
    "    try:\n",
    "        where = df_super_linkage_matrix.loc[df_super_linkage_matrix[0] == current_sub]\n",
    "        if where.shape[0] != 1:\n",
    "            where = where.loc[where[4] == numpy.NaN]\n",
    "            if where.shape[0] != 1:\n",
    "                where = where.loc[where[5] == numpy.NaN]\n",
    "        where_col = 0\n",
    "        not_where = 1\n",
    "        where.index[0]\n",
    "        \n",
    "    except IndexError:\n",
    "        where = df_super_linkage_matrix.loc[df_super_linkage_matrix[1] == current_sub]\n",
    "        if where.shape[0] != 1:\n",
    "            where = where.loc[where[4] == numpy.NaN]\n",
    "            if where.shape[0] != 1:\n",
    "                where = where.loc[where[5] == numpy.NaN]\n",
    "        where_col = 1\n",
    "        not_where = 0\n",
    "        \n",
    "    if current_sub == 59:\n",
    "        print(\"WHERE\")\n",
    "        print(where)\n",
    "        \n",
    "    return where, where_col, not_where\n",
    "\n",
    "def prepare_sub_matrix( df_sub_linkage_matrix, handy_values, data_df, sub_cluster):\n",
    "    for i in range(0, handy_values['len_sub']):\n",
    "        zero_leaf = df_sub_linkage_matrix.loc[i, 0]\n",
    "        one_leaf = df_sub_linkage_matrix.loc[i, 1]\n",
    "        if zero_leaf >= handy_values['n_sub_samples']:\n",
    "            df_sub_linkage_matrix.at[i, 0] = zero_leaf + handy_values['len_super']  + handy_values['new_location']\n",
    "\n",
    "        else:       \n",
    "            df_sub_linkage_matrix.at[i, 4] = data_df.columns.get_loc(sub_cluster.index[int(zero_leaf)])       \n",
    "            df_sub_linkage_matrix.at[i, 0] = handy_values['new_cluster']\n",
    "            handy_values['new_cluster'] += 1\n",
    "\n",
    "        if one_leaf >= handy_values['n_sub_samples']:\n",
    "            df_sub_linkage_matrix.at[i, 1] = one_leaf  + handy_values['len_super'] + handy_values['new_location']\n",
    "\n",
    "\n",
    "        else:\n",
    "            df_sub_linkage_matrix.at[i, 5]  = data_df.columns.get_loc(sub_cluster.index[int(one_leaf)])\n",
    "            df_sub_linkage_matrix.at[i, 1] = handy_values['new_cluster']\n",
    "            handy_values['new_cluster'] += 1\n",
    "\n",
    "    #set the greatest value = to 1\n",
    "    #that is the sample name that was replaced so this is done to aviod dupes\n",
    "    \n",
    "    for i in range(0, len(df_sub_linkage_matrix)):\n",
    "        if df_sub_linkage_matrix.loc[i, 0] == handy_values['len_super']:\n",
    "            df_sub_linkage_matrix.at[i, 0] = handy_values['current_sub']\n",
    "            \n",
    "\n",
    "        if df_sub_linkage_matrix.loc[i, 1] == handy_values['len_super']:\n",
    "            df_sub_linkage_matrix.at[i, 1] = handy_values['current_sub']\n",
    "        \n",
    "    #change index to be index of where it is going\n",
    "    df_sub_linkage_matrix.index = df_sub_linkage_matrix.index + handy_values['new_location']\n",
    "    \n",
    "    \n",
    "    return df_sub_linkage_matrix\n",
    "\n",
    "def prepare_super(df_super_linkage_matrix, handy_values):\n",
    "        #change super cluster so sub cluster can be added \n",
    "    for i in range(0, handy_values['len_super']):\n",
    "        \n",
    "        zero_leaf = df_super_linkage_matrix.loc[i, 0]\n",
    "        one_leaf = df_super_linkage_matrix.loc[i, 1]\n",
    "\n",
    "        if zero_leaf >= handy_values['n_super_samples']:\n",
    "            if zero_leaf - handy_values['n_super_samples'] < handy_values['new_location']:\n",
    "                df_super_linkage_matrix.at[i, 0] = df_super_linkage_matrix.loc[i, 0] + handy_values['len_sub']\n",
    "            else:\n",
    "                df_super_linkage_matrix.at[i, 0] = df_super_linkage_matrix.loc[i, 0] + (2 * handy_values['len_sub']) \n",
    "\n",
    "        if one_leaf >= handy_values['n_super_samples']:\n",
    "            if one_leaf - handy_values['n_super_samples'] < handy_values['new_location']:\n",
    "                df_super_linkage_matrix.at[i, 1] = df_super_linkage_matrix.loc[i, 1] + handy_values['len_sub']\n",
    "            else:\n",
    "                df_super_linkage_matrix.at[i, 1] = df_super_linkage_matrix.loc[i, 1] + (2 * handy_values['len_sub']) \n",
    "                \n",
    "    #drop where row and change indexs to prepare for append \n",
    "    df_super_linkage_matrix.drop(handy_values['new_location'], inplace = True)\n",
    "    \n",
    "    \n",
    "    return df_super_linkage_matrix\n",
    "\n",
    "def loop_through_clusters(total_linkage_matrix, label_df, num_row, super_dendro_labels_index, data_df):\n",
    "    transposed_label_df = label_df.transpose()\n",
    "\n",
    "    for current_sub in range(0, len(super_dendro_labels_index)):\n",
    "    #get all the values in the current sub cluster\n",
    "    \n",
    "        print(\"CURRENT SUB\")\n",
    "        print(current_sub)\n",
    "        \n",
    "        sub_cluster = (transposed_label_df.loc[transposed_label_df[num_row] == current_sub])\n",
    "        \n",
    "        df_super_linkage_matrix = total_linkage_matrix \n",
    "\n",
    "        #get where the sub cluster in in the super cluster matrix\n",
    "        where_col = 5\n",
    "        not_where = 5\n",
    "\n",
    "        where, where_col, not_where = prepare_where(df_super_linkage_matrix, current_sub)\n",
    "\n",
    "        print(\"WHERE\")\n",
    "        print(where)\n",
    "        \n",
    "        if sub_cluster.shape[0] != 1:\n",
    "\n",
    "            # run ward\n",
    "            ward_sub_cluster = sklearn.cluster.AgglomerativeClustering(affinity = \"euclidean\", n_clusters = len(sub_cluster)-1, linkage = \"average\", compute_full_tree = True, compute_distances = True).fit(sub_cluster)\n",
    "\n",
    "            sub_children_df = pd.DataFrame(ward_sub_cluster.children_)\n",
    "            sub_children_df[2] = ward_sub_cluster.distances_\n",
    "            sub_children_df[3] = numpy.NaN\n",
    "\n",
    "            sub_linkage_matrix = get_child_counts(sub_children_df)\n",
    "\n",
    "            #make them dataframes since they are better to work with\n",
    "            df_sub_linkage_matrix = pd.DataFrame(sub_linkage_matrix) \n",
    "\n",
    "            #n_samples \n",
    "            n_super_samples = len(df_super_linkage_matrix) + 1\n",
    "            n_sub_samples = len(df_sub_linkage_matrix) + 1\n",
    "\n",
    "            len_super = len(df_super_linkage_matrix)\n",
    "            len_sub = len(df_sub_linkage_matrix)\n",
    "\n",
    "            new_location = where.index[0]\n",
    "            new_cluster = len_super\n",
    "\n",
    "            #changing values in sub cluster matrix so it can be merged into super cluster \n",
    "            df_sub_linkage_matrix[4] = numpy.NaN\n",
    "            df_sub_linkage_matrix[5] = numpy.NaN\n",
    "\n",
    "            #making the dist values less then 4 so it looks nice\n",
    "            while df_sub_linkage_matrix[2][len(df_sub_linkage_matrix) - 1] > 4:\n",
    "                df_sub_linkage_matrix[2] = df_sub_linkage_matrix[2] / 2\n",
    "            \n",
    "            handy_values = {\n",
    "                'new_location':new_location,\n",
    "                'new_cluster':new_cluster,\n",
    "                'current_sub':current_sub,\n",
    "                'len_super':len_super,\n",
    "                'len_sub':len_sub,\n",
    "                'n_sub_samples':n_sub_samples,\n",
    "                'n_super_samples':n_super_samples\n",
    "            }\n",
    "\n",
    "\n",
    "            df_sub_linkage_matrix = prepare_sub_matrix(df_sub_linkage_matrix, handy_values, data_df, sub_cluster)\n",
    "            \n",
    "            #modify where line and add it to end of sub cluster matrix \n",
    "            where.at[new_location, where_col] =  new_location + len_super +  (2 * len_sub) \n",
    "\n",
    "            print(\"n_super_samples\")\n",
    "            print(n_super_samples)\n",
    "\n",
    "            if where.loc[new_location, not_where] >= n_super_samples:\n",
    "                    if where.loc[new_location, not_where] - n_super_samples < new_location:\n",
    "                        where.at[new_location, not_where] = where.loc[new_location, not_where] +len_sub\n",
    "                    else:\n",
    "                        where.at[new_location, not_where] = where.loc[new_location, not_where] + (2 * len_sub) \n",
    "\n",
    "            where.at[new_location, 3] =  where.loc[new_location, 3] + n_sub_samples\n",
    "\n",
    "            print(\"WHERE\")\n",
    "            print(where)\n",
    "\n",
    "            #a really dumb way to rename the index\n",
    "            #.setindex needs a col to set as the index \n",
    "            total_sub = pd.DataFrame(where.to_numpy(), index = [where.index[0] + n_sub_samples-1])\n",
    "            total_sub = df_sub_linkage_matrix.append(total_sub)\n",
    "\n",
    "            df_super_linkage_matrix = prepare_super(df_super_linkage_matrix, handy_values)\n",
    "\n",
    "            print(\"REMOVING\")\n",
    "            print(new_location)\n",
    "            print(\"TOTAL SUB\")\n",
    "            print(total_sub)\n",
    "            print(\"NEW LOCATION\")\n",
    "            print(new_location)\n",
    "            print(\"N_SUB_SAMPLES\")\n",
    "            print(n_sub_samples)\n",
    "            print(\"len_sub\")\n",
    "            print(len_sub)\n",
    "            print(\"len_super\")\n",
    "            print(len_super)\n",
    "\n",
    "            df_super_linkage_matrix.index = list(range(0, new_location)) + list(range(new_location + len_sub + 1 , len_super + len_sub))\n",
    "\n",
    "            #merge then sort by index \n",
    "            new_linkage_matrix = df_super_linkage_matrix.append(total_sub)\n",
    "            new_linkage_matrix.sort_index(inplace = True)\n",
    "\n",
    "            total_linkage_matrix = new_linkage_matrix\n",
    "            \n",
    "        else:\n",
    "            total_linkage_matrix[where_col + 4][where.index[0]] = data_df.columns.get_loc(sub_cluster.index[0])    \n",
    "            \n",
    "\n",
    "    print(new_linkage_matrix)\n",
    "    \n",
    "    print(\"data_df.columns\")\n",
    "    print(data_df.columns)\n",
    "    \n",
    "    return new_linkage_matrix\n",
    "\n",
    "def col_4_5_updating_1_2(new_linkage_matrix):\n",
    "    #a strange way to get all the values that are not null\n",
    "    no_nan_4 = new_linkage_matrix.loc[new_linkage_matrix[4] > -1]\n",
    "    new_0 = pd.DataFrame(no_nan_4[4])\n",
    "    new_0.columns = [0]\n",
    "\n",
    "    #a strange way to get all the values that are not null\n",
    "    no_nan_5 = new_linkage_matrix.loc[new_linkage_matrix[5] > -1]\n",
    "    new_1 = pd.DataFrame(no_nan_5[5])\n",
    "    new_1.columns = [1]\n",
    "\n",
    "    new_linkage_matrix.update(new_0)\n",
    "    new_linkage_matrix.update(new_1)\n",
    "\n",
    "    new_linkage_matrix = new_linkage_matrix.drop(4, axis = 1)\n",
    "    new_linkage_matrix = new_linkage_matrix.drop(5, axis = 1)\n",
    "    \n",
    "    return new_linkage_matrix\n",
    "\n",
    "def fix_linkage_matrix(df_sub_and_super_linkage_matrix):\n",
    "    #put the non NaN values from 4 and 5 into 1 and 2\n",
    "    #fix counts column\n",
    "    df_sub_and_super_linkage_matrix = col_4_5_updating_1_2(df_sub_and_super_linkage_matrix)\n",
    "\n",
    "    df_sub_and_super_linkage_matrix = get_child_counts(df_sub_and_super_linkage_matrix)\n",
    "\n",
    "    return df_sub_and_super_linkage_matrix\n",
    "\n",
    "#from https://stackoverflow.com/questions/28222179/save-dendrogram-to-newick-format/31878514#31878514 \n",
    "def getNewick(node, newick, parentdist, leaf_names):\n",
    "    if node.is_leaf():\n",
    "        return \"%s:%.2f%s\" % (leaf_names[node.id], parentdist - node.dist, newick)\n",
    "    else:\n",
    "        if len(newick) > 0:\n",
    "            newick = \"):%.2f%s\" % (parentdist - node.dist, newick)\n",
    "        else:\n",
    "            newick = \");\"\n",
    "        newick = getNewick(node.get_left(), newick, node.dist, leaf_names)\n",
    "        newick = getNewick(node.get_right(), \",%s\" % (newick), node.dist, leaf_names)\n",
    "        newick = \"(%s\" % (newick)\n",
    "        return newick\n",
    "\n",
    "def create_dendrogram_from_df(row_or_col, data_df):\n",
    "    #calling above methods in some order that it creates the dendrogram\n",
    "    AffinityProp = run_AffinityProp(row_or_col, data_df)\n",
    "\n",
    "    if row_or_col == \"row\":\n",
    "        data_df = data_df.transpose()\n",
    "        col_labels = AffinityProp.labels_\n",
    "        row_labels = range(0, (len(data_df.index)))\n",
    "        \n",
    "        \n",
    "    if row_or_col == \"col\":\n",
    "        \n",
    "        col_labels = AffinityProp.labels_\n",
    "        row_labels = range(0, (len(data_df.index)))\n",
    "\n",
    "\n",
    "    sorted_df, label_df = sort_by_label_list(data_df, row_labels, col_labels)\n",
    "\n",
    "    cluster_centers = get_cluster_centers(data_df, AffinityProp.cluster_centers_indices_)\n",
    "\n",
    "    super_linkage_matrix, super_r_dict = super_cluster(cluster_centers)\n",
    "\n",
    "    super_dendro_labels_index = change_labels(super_r_dict[\"leaves\"])\n",
    "    \n",
    "    print(\"(label_df): {}\".format((label_df)))\n",
    "\n",
    "    label_df = reorder_super_cluster(label_df, super_dendro_labels_index)\n",
    "\n",
    "    super_linkage_matrix = update_super_matrix(super_linkage_matrix, super_dendro_labels_index)\n",
    "\n",
    "    num_col = len(data_df.columns)\n",
    "    num_row = len(data_df.index)\n",
    "\n",
    "    sub_and_super_linkage_matrix = loop_through_clusters(super_linkage_matrix, label_df, num_row, super_dendro_labels_index, data_df) \n",
    "    \n",
    "    sub_and_super_linkage_matrix = fix_linkage_matrix(sub_and_super_linkage_matrix)\n",
    "\n",
    "    r_dict2 = run_scipy_cluster_dendrogram(sub_and_super_linkage_matrix)\n",
    "\n",
    "    df_r_dict2_labels = r_dict2[\"leaves\"]\n",
    "\n",
    "    super_and_sub_dendro_labels_index = change_labels(df_r_dict2_labels)\n",
    "\n",
    "    sas_sorted_df, sas_label_df = sort_by_label_list(data_df, row_labels, super_and_sub_dendro_labels_index)\n",
    "\n",
    "    tree = scipy.cluster.hierarchy.to_tree(sub_and_super_linkage_matrix,False)\n",
    "    newick = getNewick(tree, \"\", tree.dist, r_dict2[\"leaves\"])\n",
    "\n",
    "\n",
    "    return newick, sas_sorted_df, super_and_sub_dendro_labels_index\n",
    "\n",
    "def create_col_and_row_template(isstring, field):\n",
    "    col_and_row_template = {\n",
    "            \"squished\": False,\n",
    "            \"inlineTooltip\": False,\n",
    "            \"tooltip\": True,\n",
    "            \"highlightMatchingValues\": False,\n",
    "            \"colorBarSize\": 12,\n",
    "            \"stackedBar\": False,\n",
    "            \"display\": [\n",
    "                \"text\"\n",
    "            ],\n",
    "            \"selectionColor\": \"rgb(182,213,253)\",\n",
    "            \"colorByField\": None,\n",
    "            \"fontField\": None,\n",
    "            \"barColor\": \"#bdbdbd\",\n",
    "            \"barSize\": 40,\n",
    "            \"autoscaleAlways\": False,\n",
    "            \"minMaxReversed\": False,\n",
    "            \"field\": field,\n",
    "            \"size\": {\n",
    "                \"height\": 10\n",
    "            }\n",
    "        }\n",
    "    if isstring:\n",
    "        col_and_row_template[\"maxTextWidth\"] = 0\n",
    "        \n",
    "    return col_and_row_template\n",
    "\n",
    "def create_col_and_row_metadata_template(isstring, field, array):\n",
    "    col_and_row_metadata_template = {\n",
    "        \"properties\": {\"morpheus.dataType\": \"number\"},\n",
    "            \"name\": field,\n",
    "            \"array\": array\n",
    "          }\n",
    "    if isstring:\n",
    "        col_and_row_metadata_template[\"properties\"][\"morpheus.dataType\"] = \"string\"\n",
    "        \n",
    "    return col_and_row_metadata_template\n",
    "\n",
    "def prepare_metadata(gctoo, data_df, super_and_sub_dendro_labels_index, row_labels, num_row, num_col):\n",
    "    row_metadata = gctoo.row_metadata_df\n",
    "\n",
    "    flipped_row_labels = [len(row_labels) - x for x in row_labels]\n",
    "\n",
    "    flip_row_metadata_names_df = pd.DataFrame(flipped_row_labels)\n",
    "    flip_row_metadata_names_df.index = data_df.index\n",
    "\n",
    "    row_metadata = row_metadata.join(flip_row_metadata_names_df)\n",
    "\n",
    "    print(\"row_metadata: {}\".format(row_metadata))\n",
    "\n",
    "    sorted_row_metadata_df = row_metadata.sort_values(0)\n",
    "\n",
    "    sorted_row_metadata_df.drop(0, axis = 1, inplace = True)\n",
    "\n",
    "    col_metadata = gctoo.col_metadata_df\n",
    "    flipped_super_and_sub_dendro_labels_index = [len(super_and_sub_dendro_labels_index) - x for x in super_and_sub_dendro_labels_index]\n",
    "\n",
    "    print(\"flipped_super_and_sub_dendro_labels_index: {}\".format(flipped_super_and_sub_dendro_labels_index))\n",
    "\n",
    "    flip_col_metadata_names_df = pd.DataFrame(flipped_super_and_sub_dendro_labels_index)\n",
    "    flip_col_metadata_names_df.index = data_df.columns\n",
    "\n",
    "    col_metadata[num_col] = flip_col_metadata_names_df\n",
    "\n",
    "    sorted_col_metadata_df = col_metadata.sort_values(num_col)\n",
    "\n",
    "    sorted_col_metadata_df.drop(num_col, axis = 1, inplace = True)\n",
    "\n",
    "    print(\"sorted_col_metadata_df: {}\".format(sorted_col_metadata_df))\n",
    "\n",
    "    none_sorted_col_metadata_df = sorted_col_metadata_df.where(sorted_col_metadata_df.notnull(), None)\n",
    "\n",
    "    print(\"none_sorted_col_metadata_df: {}\".format(none_sorted_col_metadata_df))\n",
    "\n",
    "    return none_sorted_col_metadata_df, sorted_row_metadata_df\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def create_json(template_path, output_path, sas_sorted_df, col_metadata_df, row_metadata_df, col_newick, row_newick):\n",
    "    final_sorted_df_numpy =  sas_sorted_df.to_numpy()\n",
    "    flipped = numpy.flip(final_sorted_df_numpy)\n",
    "\n",
    "    template_file = open(template_path, \"r\")\n",
    "    json_object = json.load(template_file)\n",
    "    template_file.close()\n",
    "\n",
    "    json_object[\"columnDendrogram\"] = col_newick\n",
    "    json_object[\"rowDendrogram\"] = row_newick\n",
    "\n",
    "    dataset = json_object[\"dataset\"]\n",
    "\n",
    "    dataset[\"rows\"] = len(flipped)\n",
    "    dataset[\"columns\"] = len(flipped[0])\n",
    "\n",
    "    print(\"flipped.tolist()\")\n",
    "    print(flipped.tolist()[0])\n",
    "\n",
    "    dataset[\"seriesArrays\"] = [flipped.tolist()]\n",
    "\n",
    "    #reset columns and rows only necessary for now will change template so it is not later\n",
    "    json_object[\"columns\"] = []\n",
    "    json_object[\"rows\"] = []\n",
    "\n",
    "    json_object[\"columns\"].append(create_col_and_row_template(True, \"cid\"))\n",
    "    json_object[\"rows\"].append(create_col_and_row_template(True, \"rid\"))\n",
    "\n",
    "\n",
    "    dataset[\"rowMetadataModel\"][\"vectors\"] = []\n",
    "    dataset[\"columnMetadataModel\"][\"vectors\"] = []\n",
    "\n",
    "\n",
    "    sas_flipped_index = numpy.flip(list(sas_sorted_df.index))\n",
    "    sas_flipped_col = numpy.flip(list(sas_sorted_df.columns))\n",
    "                                                                                                        \n",
    "    dataset[\"rowMetadataModel\"][\"vectors\"].append(create_col_and_row_metadata_template(True, \"rid\", sas_flipped_index.tolist())) \n",
    "    dataset[\"columnMetadataModel\"][\"vectors\"].append(create_col_and_row_metadata_template(True, \"cid\", sas_flipped_col.tolist()))\n",
    "\n",
    "\n",
    "    for col in col_metadata_df.iteritems():\n",
    "        json_object[\"columns\"].append(create_col_and_row_template(True, col[0]))\n",
    "        dataset[\"columnMetadataModel\"][\"vectors\"].append(create_col_and_row_metadata_template(True, col[0], col[1].to_list())) \n",
    "\n",
    "    for row in row_metadata_df.iteritems(): \n",
    "        json_object[\"rows\"].append(create_col_and_row_template(True, row[0]))\n",
    "        dataset[\"rowMetadataModel\"][\"vectors\"].append(create_col_and_row_metadata_template(True, row[0], row[1].to_list()))\n",
    "\n",
    "    output_file = open(output_path, \"w\")\n",
    "    json.dump(json_object, output_file)\n",
    "    output_file.close()\n",
    "    return output_path\n",
    "\n",
    "def main(args):\n",
    "    gctx_path = os.path.join(\"2020_Q3_Achilles_CCLE_expression_r19144x1305.gctx\")\n",
    "    template_path = os.path.join(\"template.json\")\n",
    "    output_path = os.path.join(\"super_and_sub_file.json\")\n",
    "\n",
    "    #gctx_path = args.gctx_path\n",
    "    #template_path = args.template_path\n",
    "    #output_path = args.output_path\n",
    "\n",
    "\n",
    "    data_df_rows_chopped, gctoo = load_data(1000, gctx_path)\n",
    "    \n",
    "\n",
    "    num_col = len(data_df_rows_chopped.columns)\n",
    "    num_row = len(data_df_rows_chopped.index)\n",
    "\n",
    "    newick, sas_sorted_df, super_and_sub_dendro_labels_index = create_dendrogram_from_df(\"col\", data_df_rows_chopped)\n",
    "\n",
    "    row_newick, row_sas_sorted_df, row_super_and_sub_dendro_labels_index = create_dendrogram_from_df(\"row\", sas_sorted_df)\n",
    "\n",
    "    row_labels = list(range(0, (len(data_df_rows_chopped.index))))\n",
    "    #row_super_and_sub_dendro_labels_index = row_labels\n",
    "\n",
    "    col_metadata_df, row_metadata_df = prepare_metadata(gctoo, data_df_rows_chopped, super_and_sub_dendro_labels_index,  row_super_and_sub_dendro_labels_index, num_row, num_col)\n",
    "\n",
    "    create_json(template_path, output_path, row_sas_sorted_df.transpose(), col_metadata_df, row_metadata_df, newick, row_newick)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "    logger.info(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8ec92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "output_path = main(\"args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2631a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
